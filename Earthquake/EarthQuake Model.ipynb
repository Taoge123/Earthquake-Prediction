{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Dataset:\n",
    "    @staticmethod\n",
    "    def load_from_file(filename):\n",
    "        '''\n",
    "        Load and return data from file\n",
    "        :param filename: path of the database.csv file\n",
    "        :return: (date, latitude, longitude, magnitude) (np.array)\n",
    "        '''\n",
    "        date, latitude, longitude, magnitude = [], [], [], []\n",
    "\n",
    "        with open(filename, \"r\") as f:\n",
    "            f.readline()  # Skip first line\n",
    "\n",
    "            for line in f:\n",
    "                elements = line.split(',')\n",
    "                try:\n",
    "                    date.append(datetime.strptime(f\"{elements[0]} {elements[1]}\", \"%m/%d/%Y %H:%M:%S\"))\n",
    "                    latitude.append(float(elements[2]))\n",
    "                    longitude.append(float(elements[3]))\n",
    "                    magnitude.append(elements[8])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        return np.array(date), np.float32(latitude), np.float32(longitude), np.float32(magnitude)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_date(array):\n",
    "        '''\n",
    "        Normalize datetime array\n",
    "        :param array: array to normalize\n",
    "        :return: normalized array (np.array)\n",
    "        '''\n",
    "        min_data = min(array)\n",
    "        max_data = max(array)\n",
    "        delta = max_data - min_data\n",
    "\n",
    "        return np.float32([(d - min_data).total_seconds() / delta.total_seconds() for d in array])\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_cord(latitude, longitude):\n",
    "        '''\n",
    "        Normalize GPS cord array, assuming the earth is shpherical\n",
    "        :param latitude: latitude array to normalize\n",
    "        :param longitude: longitude array to normalize\n",
    "        :return: normalized arrays (np.array)\n",
    "        '''\n",
    "        rad_lat = np.deg2rad(latitude)\n",
    "        rad_lon = np.deg2rad(longitude)\n",
    "\n",
    "        x = np.cos(rad_lat) * np.cos(rad_lon)\n",
    "        y = np.cos(rad_lat) * np.sin(rad_lon)\n",
    "        z = np.sin(rad_lat)\n",
    "\n",
    "        return x, y, z\n",
    "\n",
    "    @staticmethod\n",
    "    def vectorize(date, latitude, longitude):\n",
    "        '''\n",
    "        Transform given array in a vectors to feed NN\n",
    "        :param date: date array\n",
    "        :param latitude: latitude array\n",
    "        :param longitude: longitude array\n",
    "        :return: np.array\n",
    "        '''\n",
    "        return np.concatenate(Dataset.normalize_cord(latitude, longitude) + (Dataset.normalize_date(date),))\\\n",
    "            .reshape((4, len(date)))\\\n",
    "            .swapaxes(0, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Math:\n",
    "    @staticmethod\n",
    "    def sigmoid(x, deriv=False):\n",
    "        '''\n",
    "        SigmoÃ¯d function\n",
    "        :param x: np.array\n",
    "        :param deriv: derivate wanted ?\n",
    "        :return:\n",
    "        '''\n",
    "        if deriv:\n",
    "            return x * (1 - x)\n",
    "\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x, deriv=False):\n",
    "        '''\n",
    "        Rectifier function\n",
    "        :param x: np.array\n",
    "        :param deriv: derivate wanted ?\n",
    "        :return:\n",
    "        '''\n",
    "        if deriv:\n",
    "            return np.ones_like(x) * (x > 0)\n",
    "\n",
    "        return x * (x > 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def new_parameters(x, x_min, x_max, radius):\n",
    "        '''\n",
    "        Generate new random parameters in the sphere of center and radius given\n",
    "        :param x: center on the sphere\n",
    "        :param x_min: minmium value returned\n",
    "        :param x_max: maximum value returned\n",
    "        :param radius: radius\n",
    "        :return: new parameter\n",
    "        '''\n",
    "        alpha = 2 * np.random.random() - 1\n",
    "        new_x = x + radius * alpha\n",
    "\n",
    "        if new_x < x_min:\n",
    "            return x_min\n",
    "        elif new_x > x_max:\n",
    "            return x_max\n",
    "\n",
    "        return new_x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Generator:\n",
    "    @staticmethod\n",
    "    def gen_random_batch(batch_size, X, Y):\n",
    "        '''\n",
    "        Generator for random batch\n",
    "        :param batch_size: size or the returned batches\n",
    "        :param X: X array\n",
    "        :param Y: Y array\n",
    "        :return: random batches of the given size\n",
    "        '''\n",
    "        while True:\n",
    "            index = np.arange(X.shape[0])\n",
    "            np.random.shuffle(index)\n",
    "\n",
    "            s_X, s_Y = X[index], Y[index]\n",
    "            for i in range(X.shape[0] // batch_size):\n",
    "                yield (X[i * batch_size:(i + 1) * batch_size], Y[i * batch_size:(i + 1) * batch_size])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_batch(batch_size, X, Y):\n",
    "        '''\n",
    "        Generator to split givens arrays in smaller batches\n",
    "        :param batch_size: size or the returned batches\n",
    "        :param X: X array\n",
    "        :param Y: Y array\n",
    "        :return: random batches of the given size\n",
    "        '''\n",
    "        if X.shape[0] % batch_size != 0:\n",
    "            print(\"[/!\\ Warning /!\\] the full set will not be executed because of a poor choice of batch_size\")\n",
    "\n",
    "        for i in range(X.shape[0] // batch_size):\n",
    "            yield X[i * batch_size:(i + 1) * batch_size], Y[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "learning rate: 0.0005924019291547681\n",
      "momentum: 0.95\n",
      "batch size: 62\n",
      "max epochs: 5610\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 1\n",
      "learning rate: 0.0007515215123387506\n",
      "momentum: 0.9015596733083081\n",
      "batch size: 68\n",
      "max epochs: 16055\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 2\n",
      "learning rate: 0.0005732991071473535\n",
      "momentum: 0.9468425567717325\n",
      "batch size: 55\n",
      "max epochs: 1880\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 3\n",
      "learning rate: 0.0004129397731704485\n",
      "momentum: 0.95\n",
      "batch size: 54\n",
      "max epochs: 7573\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 4\n",
      "learning rate: 0.00044411875043268167\n",
      "momentum: 0.8982943700721157\n",
      "batch size: 67\n",
      "max epochs: 1923\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 5\n",
      "learning rate: 0.0011912198323843865\n",
      "momentum: 0.95\n",
      "batch size: 66\n",
      "max epochs: 6956\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 6\n",
      "learning rate: 0.0014452452103853582\n",
      "momentum: 0.8582097793728966\n",
      "batch size: 69\n",
      "max epochs: 6162\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 7\n",
      "learning rate: 0.0011987117816078389\n",
      "momentum: 0.95\n",
      "batch size: 67\n",
      "max epochs: 9421\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 8\n",
      "learning rate: 0.0005107890702710356\n",
      "momentum: 0.95\n",
      "batch size: 56\n",
      "max epochs: 2322\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 9\n",
      "learning rate: 0.001318470934552986\n",
      "momentum: 0.8622127023145376\n",
      "batch size: 68\n",
      "max epochs: 10706\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 10\n",
      "learning rate: 0.0013518513786149717\n",
      "momentum: 0.95\n",
      "batch size: 60\n",
      "max epochs: 2061\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 11\n",
      "learning rate: 0.0005404170807401969\n",
      "momentum: 0.9065308631922412\n",
      "batch size: 53\n",
      "max epochs: 3224\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 12\n",
      "learning rate: 0.0013522314398037932\n",
      "momentum: 0.95\n",
      "batch size: 59\n",
      "max epochs: 2049\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 13\n",
      "learning rate: 0.0008279836998256486\n",
      "momentum: 0.8802518294936255\n",
      "batch size: 70\n",
      "max epochs: 9598\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 14\n",
      "learning rate: 0.00045591588554463674\n",
      "momentum: 0.9430592418935857\n",
      "batch size: 70\n",
      "max epochs: 4040\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 15\n",
      "learning rate: 0.0010059961271932805\n",
      "momentum: 0.95\n",
      "batch size: 69\n",
      "max epochs: 5640\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 16\n",
      "learning rate: 0.001648492349582339\n",
      "momentum: 0.9457917974266055\n",
      "batch size: 60\n",
      "max epochs: 2737\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 17\n",
      "learning rate: 0.0008414620274646451\n",
      "momentum: 0.95\n",
      "batch size: 63\n",
      "max epochs: 11618\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 18\n",
      "learning rate: 0.00037015644788889113\n",
      "momentum: 0.8608313008102243\n",
      "batch size: 68\n",
      "max epochs: 4404\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 19\n",
      "learning rate: 0.0003249934639604686\n",
      "momentum: 0.9349260740109777\n",
      "batch size: 67\n",
      "max epochs: 3963\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 20\n",
      "learning rate: 0.0014586285477449228\n",
      "momentum: 0.9383484889987469\n",
      "batch size: 65\n",
      "max epochs: 8156\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 21\n",
      "learning rate: 0.0004879195877515712\n",
      "momentum: 0.95\n",
      "batch size: 71\n",
      "max epochs: 5633\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 22\n",
      "learning rate: 0.0010029217233462886\n",
      "momentum: 0.95\n",
      "batch size: 52\n",
      "max epochs: 14523\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 23\n",
      "learning rate: 0.001650722246873849\n",
      "momentum: 0.95\n",
      "batch size: 65\n",
      "max epochs: 17680\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 24\n",
      "learning rate: 0.0008881593694556735\n",
      "momentum: 0.95\n",
      "batch size: 70\n",
      "max epochs: 2336\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 25\n",
      "learning rate: 0.00031817540918474\n",
      "momentum: 0.8620228302397137\n",
      "batch size: 69\n",
      "max epochs: 2812\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 26\n",
      "learning rate: 0.000682767301429005\n",
      "momentum: 0.911745146623078\n",
      "batch size: 63\n",
      "max epochs: 2977\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 27\n",
      "learning rate: 0.00036237079551264387\n",
      "momentum: 0.95\n",
      "batch size: 54\n",
      "max epochs: 10236\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 28\n",
      "learning rate: 0.0006539408082971306\n",
      "momentum: 0.95\n",
      "batch size: 64\n",
      "max epochs: 7221\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 29\n",
      "learning rate: 0.0004830181018407956\n",
      "momentum: 0.8704048769435425\n",
      "batch size: 69\n",
      "max epochs: 1978\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 30\n",
      "learning rate: 0.00129903700441605\n",
      "momentum: 0.9248587146026777\n",
      "batch size: 68\n",
      "max epochs: 3626\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 31\n",
      "learning rate: 0.0003427672631246541\n",
      "momentum: 0.95\n",
      "batch size: 71\n",
      "max epochs: 4860\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 32\n",
      "learning rate: 0.00031141718082958\n",
      "momentum: 0.95\n",
      "batch size: 61\n",
      "max epochs: 2495\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 33\n",
      "learning rate: 0.0009820223704779375\n",
      "momentum: 0.8653178988461794\n",
      "batch size: 54\n",
      "max epochs: 2884\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 34\n",
      "learning rate: 0.000476013419880646\n",
      "momentum: 0.9131216121770434\n",
      "batch size: 68\n",
      "max epochs: 7207\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 35\n",
      "learning rate: 0.0018513091707777723\n",
      "momentum: 0.9333306868331984\n",
      "batch size: 59\n",
      "max epochs: 7577\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 36\n",
      "learning rate: 0.001381398493279627\n",
      "momentum: 0.9417776348485682\n",
      "batch size: 54\n",
      "max epochs: 6176\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 37\n",
      "learning rate: 0.00047176580106751795\n",
      "momentum: 0.8549567064280781\n",
      "batch size: 62\n",
      "max epochs: 6616\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 38\n",
      "learning rate: 0.00033922871476981816\n",
      "momentum: 0.930661778298523\n",
      "batch size: 57\n",
      "max epochs: 3065\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 39\n",
      "learning rate: 0.0007815079334024824\n",
      "momentum: 0.9306600583695832\n",
      "batch size: 59\n",
      "max epochs: 4877\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 40\n",
      "learning rate: 0.0005268283410573279\n",
      "momentum: 0.95\n",
      "batch size: 63\n",
      "max epochs: 7276\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 41\n",
      "learning rate: 0.001087140822026374\n",
      "momentum: 0.95\n",
      "batch size: 66\n",
      "max epochs: 5214\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 42\n",
      "learning rate: 0.001002461898084541\n",
      "momentum: 0.868426068830165\n",
      "batch size: 66\n",
      "max epochs: 3690\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 43\n",
      "learning rate: 0.0007515562231730667\n",
      "momentum: 0.8778581208515277\n",
      "batch size: 59\n",
      "max epochs: 4754\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 44\n",
      "learning rate: 0.0003661321318415576\n",
      "momentum: 0.913066192094125\n",
      "batch size: 69\n",
      "max epochs: 4433\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 45\n",
      "learning rate: 0.0007437958248562919\n",
      "momentum: 0.9349932417856331\n",
      "batch size: 66\n",
      "max epochs: 9997\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 46\n",
      "learning rate: 0.00036865471982378033\n",
      "momentum: 0.95\n",
      "batch size: 54\n",
      "max epochs: 13413\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 47\n",
      "learning rate: 0.0015603584605502706\n",
      "momentum: 0.95\n",
      "batch size: 64\n",
      "max epochs: 4777\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 48\n",
      "learning rate: 0.0010681995366666512\n",
      "momentum: 0.9156554718626719\n",
      "batch size: 71\n",
      "max epochs: 7757\n",
      "error: 5.873358951878344\n",
      "\n",
      "iteration: 49\n",
      "learning rate: 0.0012961765987894495\n",
      "momentum: 0.95\n",
      "batch size: 52\n",
      "max epochs: 3701\n",
      "error: 5.873358951878344\n",
      "\n",
      "best error: 5.873358951878344\n",
      "best learning rate log: -3.227383535870096\n",
      "best momentum: 0.95\n",
      "best batch size: 62\n",
      "best max epochs log: 3.7490136107974097\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    date, latitude, longitude, magnitude = Dataset.load_from_file(\"database.csv\")\n",
    "    data_size = len(date)\n",
    "    vectorsX, vectorsY = Dataset.vectorize(date, latitude, longitude), magnitude.reshape((data_size, 1))\n",
    "\n",
    "    # Split vectors into train / eval sets\n",
    "    eval_set_size = int(0.1 * data_size)\n",
    "    index = np.arange(data_size)\n",
    "    np.random.shuffle(index)\n",
    "    trainX, trainY = vectorsX[index[eval_set_size:]], vectorsY[index[eval_set_size:]]\n",
    "    evalX, evalY = vectorsX[index[:eval_set_size]], vectorsY[index[:eval_set_size]]\n",
    "\n",
    "    # randomly initialize our weights with mean 0\n",
    "    syn0_origin = 2 * np.random.random((trainX.shape[1], 32)) - 1\n",
    "    syn1_origin = 2 * np.random.random((32, trainY.shape[1])) - 1\n",
    "\n",
    "    # Placeholder for hyperparameters\n",
    "    best_error = 9999\n",
    "    best_learning_rate_log = -3\n",
    "    best_momentum = 0.9\n",
    "    best_batch_size = 64\n",
    "    best_max_epochs_log = 4\n",
    "    learning_rate_log = None\n",
    "    momentum = None\n",
    "    batch_size = None\n",
    "    max_epochs_log = None\n",
    "\n",
    "    for i in range(50):\n",
    "        # Hyperparameters\n",
    "        learning_rate_log = Math.new_parameters(best_learning_rate_log, -5, -1, 0.5)  # log range from 0.0001 to 0.1\n",
    "        momentum = Math.new_parameters(best_momentum, 0.5, 0.95, 0.1)  # linear range from 0.5 to 0.9\n",
    "        batch_size = np.int64(Math.new_parameters(best_batch_size, 10, 128, 10))  # linear range from 10 to 128\n",
    "        max_epochs_log = Math.new_parameters(best_max_epochs_log, 3, 5, 0.5)  # log range from 1000 to 100000\n",
    "\n",
    "        learning_rate = np.power(10, learning_rate_log)\n",
    "        max_epochs = np.int64(np.power(10, max_epochs_log))\n",
    "\n",
    "        # Display hyperparameters\n",
    "        print(f\"iteration: {i}\")\n",
    "        print(f\"learning rate: {learning_rate}\")\n",
    "        print(f\"momentum: {momentum}\")\n",
    "        print(f\"batch size: {batch_size}\")\n",
    "        print(f\"max epochs: {max_epochs}\")\n",
    "\n",
    "        # reset weight\n",
    "        syn0 = copy.deepcopy(syn0_origin)\n",
    "        syn1 = copy.deepcopy(syn1_origin)\n",
    "\n",
    "        # initialize momentum\n",
    "        momentum_syn0 = np.zeros_like(syn0)\n",
    "        momentum_syn1 = np.zeros_like(syn1)\n",
    "\n",
    "        # get batch generator\n",
    "        batch_gen = Generator.gen_random_batch(batch_size, trainX, trainY)\n",
    "\n",
    "        # Train model\n",
    "        for j in range(max_epochs):\n",
    "            # Get Batch\n",
    "            batch = next(batch_gen)\n",
    "\n",
    "            # feed forward\n",
    "            l0 = batch[0]\n",
    "            l1 = Math.sigmoid(np.dot(l0, syn0))\n",
    "            l2 = Math.relu(np.dot(l1, syn1))\n",
    "\n",
    "            # l2 error & delta\n",
    "            l2_error = batch[1] - l2\n",
    "            l2_delta = l2_error * Math.relu(l2, deriv=True)\n",
    "\n",
    "            # l1 error & delta\n",
    "            l1_error = l2_delta.dot(syn1.T)\n",
    "            l1_delta = l1_error * Math.sigmoid(l1, deriv=True)\n",
    "\n",
    "            # momentum\n",
    "            momentum_syn1 = momentum * momentum_syn1 + l1.T.dot(l2_delta) * learning_rate\n",
    "            momentum_syn0 = momentum * momentum_syn0 + l0.T.dot(l1_delta) * learning_rate\n",
    "\n",
    "            # Apply momentum correction\n",
    "            syn1 += momentum_syn1\n",
    "            syn0 += momentum_syn0\n",
    "\n",
    "        # Evaluate model\n",
    "        current_error = 0\n",
    "        for batch in Generator.get_batch(10, evalX, evalY):\n",
    "            # feed forward\n",
    "            l0 = batch[0]\n",
    "            l1 = Math.sigmoid(np.dot(l0, syn0))\n",
    "            l2 = Math.relu(np.dot(l1, syn1))\n",
    "\n",
    "            # accumulate error\n",
    "            current_error += np.sum(np.abs(batch[1] - l2))\n",
    "        current_error /= eval_set_size\n",
    "\n",
    "        print(f\"error: {current_error}\\n\")\n",
    "\n",
    "        if current_error < best_error:\n",
    "            best_error = current_error\n",
    "            best_learning_rate_log = learning_rate_log\n",
    "            best_momentum = momentum\n",
    "            best_batch_size = batch_size\n",
    "            best_max_epochs_log = max_epochs_log\n",
    "\n",
    "    print(f\"best error: {best_error}\")\n",
    "    print(f\"best learning rate log: {best_learning_rate_log}\")\n",
    "    print(f\"best momentum: {best_momentum}\")\n",
    "    print(f\"best batch size: {best_batch_size}\")\n",
    "    print(f\"best max epochs log: {best_max_epochs_log}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
